<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Jonah Gabry and Ben Goodrich" />

<meta name="date" content="2018-11-08" />

<title>Estimating Ordinal Regression Models with rstanarm</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Estimating Ordinal Regression Models with rstanarm</h1>
<h4 class="author"><em>Jonah Gabry and Ben Goodrich</em></h4>
<h4 class="date"><em>2018-11-08</em></h4>


<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#likelihood">Likelihood</a></li>
<li><a href="#priors">Priors</a></li>
<li><a href="#example">Example</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
</div>

<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{stan_polr: Ordinal Models}
-->
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>This vignette explains how to estimate models for ordinal outcomes using the <code>stan_polr</code> function in the <strong>rstanarm</strong> package.</p>
<p>Steps 3 and 4 are covered in more depth by the vignette entitled <a href="rstanarm.html">“How to Use the <strong>rstanarm</strong> Package”</a>. This vignette focuses on Step 1.</p>
<p>One of the strengths of doing MCMC with Stan — as opposed to a Gibbs sampler — is that reparameterizations are essentially costless, which allows the user to specify priors on parameters that are either more intuitive, numerically stable, or computationally efficient without changing the posterior distribution of the parameters that enter the likelihood. Advantageous parameterizations are already built into the Stan programs used in the <strong>rstanarm</strong> package, so it is just a matter of using these vignettes to explain how the priors work in the context of these reparameterizations.</p>
</div>
<div id="likelihood" class="section level1">
<h1>Likelihood</h1>
<p>Ordinal outcomes fall in one of <span class="math inline">\(J\)</span> categories. One way to motivate an ordinal model is to introduce a latent variable, <span class="math inline">\(y^\ast\)</span>, that is related to the observed outcomes via an observation mechanism: <span class="math display">\[y=\begin{cases}
1 &amp; \mbox{if }y^{\ast}&lt;\zeta_{1}\\
2 &amp; \mbox{if }\zeta_{1}\leq y^{\ast}&lt;\zeta_{2}\\
\vdots\\
J &amp; \mbox{if }\zeta_{J-1}\leq y^{\ast}
\end{cases},\]</span> where <span class="math inline">\(\boldsymbol{\zeta}\)</span> is a vector of cutpoints of length <span class="math inline">\(J-1\)</span>.</p>
<p>Then <span class="math inline">\(y^\ast\)</span> is modeled as a linear function of <span class="math inline">\(K\)</span> predictors <span class="math display">\[y^\ast = \mu + \epsilon = \mathbf{x}^\top \boldsymbol{\beta} + \epsilon,\]</span> where <span class="math inline">\(\epsilon\)</span> has mean zero and unit scale but can be specified as being drawn from one of several distributions. Note that there is no “intercept” in this model since the data cannot distinguish an intercept from the cutpoints. However, if <span class="math inline">\(J = 2\)</span>, then <span class="math inline">\(\zeta_1\)</span> can be referred to as either the cutpoint or the intercept.</p>
<p>A Bayesian can treat <span class="math inline">\(y^\ast\)</span> as another unknown parameter, although for computational efficiency the Stan code essentially integrates each <span class="math inline">\(y^\ast\)</span> out of the posterior distribution, leaving the posterior distribution of <span class="math inline">\(\boldsymbol{\beta}\)</span> and <span class="math inline">\(\boldsymbol{\zeta}\)</span>. Nevertheless, it is useful to motivate the model theoretically as if <span class="math inline">\(y^\ast\)</span> were just an unknown parameter with a distribution truncated by the relevant element(s) of <span class="math inline">\(\boldsymbol{\zeta}\)</span>.</p>
</div>
<div id="priors" class="section level1">
<h1>Priors</h1>
<p>If <span class="math inline">\(y^\ast\)</span> were observed we would simply have a linear regression model for it, and the description of the priors in the vignette entitled <a href="lm.html">“Estimating Linear Models with the <strong>rstanarm</strong> Package”</a> would apply directly. Another way to say the same thing is <em>conditional</em> on a realization of <span class="math inline">\(y^\ast\)</span>, we have a linear regression model and the description of the priors in the other <a href="lm.html">vignette</a> does apply (and should be read before continuing with this subsection).</p>
<p>The <code>stan_lm</code> function essentially specifies a prior on <span class="math inline">\(\boldsymbol{\theta} = \mathbf{R}^{-1} \boldsymbol{\beta}\)</span>, where <span class="math inline">\(\mathbf{R}\)</span> is the upper triangular matrix in the QR decomposition of the design matrix, <span class="math inline">\(\mathbf{X} = \mathbf{Q} \mathbf{R}\)</span>. Furthermore, in <code>stan_lm</code>, <span class="math inline">\(\sigma_{\epsilon} = \sigma_y \sqrt{1 - R^2}\)</span> where <span class="math inline">\(R^2\)</span> is the proportion of variance in the outcome that is attributable to the coefficients in a linear model.</p>
<p>The main difference in the context of a model for an ordinal outcome is that the scale of <span class="math inline">\(y^\ast\)</span> is not identified by the data. Thus, the ordinal model specifies that <span class="math inline">\(\sigma_{\epsilon} = 1\)</span>, which implies that <span class="math inline">\(\sigma_{y^\ast} = 1 / \sqrt{1 - R^2}\)</span> is an intermediate parameter rather than a primitive parameter.</p>
<p>It is somewhat more difficult to specify a prior value for the <span class="math inline">\(R^2\)</span> in an ordinal model because <span class="math inline">\(R^2\)</span> refers to the proportion of variance in the  <span class="math inline">\(y^\ast\)</span> that is attributable to the predictors under a linear model. In general, the <span class="math inline">\(R^2\)</span> tends to be lower in an ordinal model than in a linear model where the continuous outcome is observed.</p>
<p>The other difference is that an ordinal model does not have a global intercept but rather a vector of <span class="math inline">\(J-1\)</span> cutpoints. The implied prior on these cutpoints used by the <strong>rstanarm</strong> package is somewhat novel. The user instead specifies a Dirichlet prior on <span class="math inline">\(\Pr\left(y=j \, \left.\right| \, \overline{\mathbf{x}} \right)\)</span>, which is to say the prior probability of the outcome falling in each of the <span class="math inline">\(J\)</span> categories given that the predictors are at their sample means. The Dirichlet prior is for a simplex random variable, whose elements are non-negative and sum to <span class="math inline">\(1\)</span>. The Dirichlet PDF can be written as <span class="math display">\[f\left(\boldsymbol{\pi}|\boldsymbol{\alpha}\right) \propto 
\prod_{j=1}^J{\pi_j^{\alpha_j - 1}}, \]</span> where <span class="math inline">\(\boldsymbol{\pi}\)</span> is a simplex vector such that <span class="math inline">\(\pi_j = \Pr\left(y=j \, \left.\right| \, \overline{\mathbf{x}} \right)\)</span>.</p>
<p>The Dirichlet prior is one of the easiest to specify because the so-called “concentration” hyperparameters <span class="math inline">\(\boldsymbol{\alpha}\)</span> can be interpreted as prior counts, i.e., prior observations for each of the J categories (although they need not be integers). If <span class="math inline">\(\alpha_j = 1\)</span> for every <span class="math inline">\(j\)</span> (the default used by <strong>rstanarm</strong>) then the Dirichlet prior is jointly uniform over the space of these simplexes. This corresponds to a prior count of one observation falling in each of the <span class="math inline">\(J\)</span> ordinal categories when the predictors are at their sample means and conveys the reasonable but weak prior information that no category has probability zero. If, for each <span class="math inline">\(j\)</span>, <span class="math inline">\(\alpha_j = \alpha &gt; 1\)</span> then the prior mode is that the <span class="math inline">\(J\)</span> categories are equiprobable, with prior probability <span class="math inline">\(1/J\)</span> of the outcome falling in each of the <span class="math inline">\(J\)</span> categories. The larger the value of <span class="math inline">\(\alpha\)</span> the more sharply peaked the distribution is at the mode.</p>
<p>The <span class="math inline">\(j\)</span>-th cutpoint <span class="math inline">\(\zeta_j\)</span> is then given by <span class="math display">\[\zeta_j = F_{y^\ast}^{-1}\left(\sum_{i=1}^j{\pi_i}\right),\]</span> where <span class="math inline">\(F_{y^\ast}^{-1}\)</span> is an inverse CDF function, which depends on the assumed distribution of <span class="math inline">\(y^\ast\)</span>. Common choices include the normal and logistic distributions. The scale parameter of this distribution is again <span class="math inline">\(\sigma_{y^\ast} = 1/\sqrt{1 - R^2}\)</span>. In short, by making each <span class="math inline">\(\zeta_j\)</span> a function of <span class="math inline">\(\boldsymbol{\pi}\)</span>, it allows us to specify a Dirichlet prior on <span class="math inline">\(\boldsymbol{\pi}\)</span>, which is simpler than specifying a prior on <span class="math inline">\(\boldsymbol{\zeta}\)</span> directly.</p>
</div>
<div id="example" class="section level1">
<h1>Example</h1>
<p>In this section, we start with an ordinal model of tobacco consumption as a function of age and alcohol consumption. Frequentist estimates can be obtained using the <code>polr</code> function in the <strong>MASS</strong> package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
<span class="kw">print</span>(<span class="kw">polr</span>(tobgp ~<span class="st"> </span>agegp +<span class="st"> </span>alcgp, <span class="dt">data =</span> esoph), <span class="dt">digits =</span> <span class="dv">1</span>)</code></pre></div>
<p>To obtain Bayesian estimates, we prepend <code>stan_</code> and specify the priors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rstanarm)
post0 &lt;-<span class="st"> </span><span class="kw">stan_polr</span>(tobgp ~<span class="st"> </span>agegp +<span class="st"> </span>alcgp, <span class="dt">data =</span> esoph, 
                   <span class="dt">prior =</span> <span class="kw">R2</span>(<span class="fl">0.25</span>), <span class="dt">prior_counts =</span> <span class="kw">dirichlet</span>(<span class="dv">1</span>),
                   <span class="dt">chains =</span> CHAINS, <span class="dt">cores =</span> CORES, <span class="dt">seed =</span> SEED, <span class="dt">iter =</span> <span class="dv">200</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(post0, <span class="dt">digits =</span> <span class="dv">1</span>)</code></pre></div>
<p>The point estimates, represented by the posterior medians, are qualitatively similar to the maximum-likelihood estimates but are somewhat shrunk toward zero due to the regularizing prior on the coefficients. Since these cutpoints are actually <em>known</em>, it would be more appropriate for the model to take that into account, but <code>stan_polr</code> does not currently support that.</p>
<p>Next, we utilize an example from the <strong>MASS</strong> package where low birthweight is the binary outcome of interest. First, we recode some of the variables:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;birthwt&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;MASS&quot;</span>)
birthwt$race &lt;-<span class="st"> </span><span class="kw">factor</span>(birthwt$race, <span class="dt">levels =</span> <span class="dv">1</span>:<span class="dv">3</span>, 
                       <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;white&quot;</span>, <span class="st">&quot;black&quot;</span>, <span class="st">&quot;other&quot;</span>))
birthwt$bwt &lt;-<span class="st"> </span>birthwt$bwt /<span class="st"> </span><span class="dv">1000</span> <span class="co"># convert from grams to kilograms</span>
birthwt$low &lt;-<span class="st"> </span><span class="kw">factor</span>(birthwt$low, <span class="dt">levels =</span> <span class="dv">0</span>:<span class="dv">1</span>, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;no&quot;</span>, <span class="st">&quot;yes&quot;</span>))</code></pre></div>
<p>It is usually a good idea to rescale variables by constants so that all the numbers are in single or double digits. We start by estimating a linear model for birthweight in kilograms, flipping the sign so that positive coefficients are associated with <em>lower</em> birthweights.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">post1 &lt;-<span class="st"> </span><span class="kw">stan_lm</span>(-bwt ~<span class="st"> </span>smoke +<span class="st"> </span>age +<span class="st"> </span>race +<span class="st"> </span>ptl +<span class="st"> </span>ht +<span class="st"> </span>ftv,
                 <span class="dt">data =</span> birthwt, <span class="dt">prior =</span> <span class="kw">R2</span>(<span class="fl">0.5</span>), 
                 <span class="dt">chains =</span> CHAINS, <span class="dt">cores =</span> CORES, <span class="dt">seed =</span> SEED)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(post1)</code></pre></div>
<p>Next, we estimate an “ordinal” model for the incidence of low birthweight, which is defined as a birth weight of less than <span class="math inline">\(2.5\)</span> kilograms. Even though this outcome is binary, a binary variable is a special case of an ordinal variable with <span class="math inline">\(J=2\)</span> categories and is acceptable to <code>stan_polr</code>. We can think of <code>bwt</code> as something proportional to <span class="math inline">\(y^\ast\)</span> and pretend that it is not observed, forcing us to estimate an ordinal model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">post2 &lt;-<span class="st"> </span><span class="kw">stan_polr</span>(low ~<span class="st"> </span>smoke +<span class="st"> </span>age +<span class="st"> </span>race +<span class="st"> </span>ptl +<span class="st"> </span>ht +<span class="st"> </span>ftv, <span class="dt">data =</span> birthwt,
                   <span class="dt">prior =</span> <span class="kw">R2</span>(<span class="fl">0.5</span>), <span class="dt">prior_counts =</span> <span class="kw">dirichlet</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>)), 
                   <span class="dt">method =</span> <span class="st">&quot;probit&quot;</span>, 
                   <span class="dt">chains =</span> CHAINS, <span class="dt">cores =</span> CORES, <span class="dt">seed =</span> SEED)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">loo</span>(post2))</code></pre></div>
<p>This prior seems to have worked well in this case because none of the points in the plot are above <span class="math inline">\(0.5\)</span>, which would have indicated the the posterior is very sensitive to those observations. If we compare the estimated coefficients,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">cbind</span>(<span class="dt">Linear =</span> <span class="kw">coef</span>(post1), <span class="dt">Ordinal =</span> <span class="kw">coef</span>(post2), 
            <span class="dt">Rescaled =</span> <span class="kw">coef</span>(post1) /<span class="st"> </span><span class="kw">sigma</span>(post1)), <span class="dv">3</span>)</code></pre></div>
<p>they have the same signs and similar magnitudes, with the exception of the “Intercept”. In an ordinal model where the outcome only has <span class="math inline">\(J=2\)</span> categories, this “Intercept” is actually <span class="math inline">\(\zeta_1\)</span>, but it is more conventional to call it the “Intercept” so that it agrees with <code>stan_glm</code> when <code>family = binomial(link = 'probit')</code>. Recall that <span class="math inline">\(\sigma_{\epsilon} = 1\)</span> in an ordinal model, so if we rescale the coefficients from a linear model by dividing by the posterior median of <span class="math inline">\(\sigma\)</span>, the resulting coefficients are even closer to those of the ordinal model.</p>
<p>This illustrates the fundamental similarity between a linear model for a continuous observed outcome and a linear model for a latent <span class="math inline">\(y^\ast\)</span> that generates an ordinal observed outcome. The main difference is when the outcome is continuous and observed, we can estimate the scale of the errors meaningfully. When the outcome is ordinal, we can only fix the scale of the latent errors to <span class="math inline">\(1\)</span> arbitrarily.</p>
<p>Finally, when <span class="math inline">\(J = 2\)</span>, the <code>stan_polr</code> function allows you to specify non-<code>NULL</code> values of the <code>shape</code> and <code>rate</code> arguments, which implies a “scobit” likelihood where the probability of success is given by <span class="math inline">\(F\left(y^\ast \right)^\alpha\)</span>, where <span class="math inline">\(F\left(\right)\)</span> is the logistic CDF and <span class="math inline">\(\alpha &gt; 0\)</span> is a skewing parameter that has a gamma prior with a given <code>shape</code> and <code>rate</code>. If <span class="math inline">\(\alpha \neq 1\)</span>, then the relationship between <span class="math inline">\(y^\ast\)</span> and the probability of success is asymmetric. In principle, it seems appropriate to estimate <span class="math inline">\(\alpha\)</span> but in practice, a lot of data is needed to estimate <span class="math inline">\(\alpha\)</span> with adequate precision. In the previous example, if we specify <code>shape = 2</code> and <code>rate = 2</code> to reflect the prior beliefs that <span class="math inline">\(\alpha\)</span> is expected to be <span class="math inline">\(1\)</span> but has a variance of <span class="math inline">\(\frac{1}{2}\)</span>, then the <code>loo</code> calculation yields many Pareto shape parameters that are excessively large. However, with more than <span class="math inline">\(189\)</span> observations, such a model may be more fruitful.</p>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>The posterior distribution for an ordinal model requires priors on the coefficients and the cutpoints. The priors used by the <code>stan_polr</code> function are unconventional but should work well for a variety of problems. The prior on the coefficients is essentially the same as that used by the <code>stan_lm</code> function but omits a scale parameter because the standard deviation of the latent <span class="math inline">\(y^\ast\)</span> is not identified by the data. The cutpoints are conditionally deterministic given a simplex vector for the probability of falling in each of the <span class="math inline">\(J\)</span> ordinal categories given that the predictors are at their sample means. Thus, a Dirichlet prior — which is relatively easy to specify and has a good default of jointly uniform — on this simplex completes the posterior distribution.</p>
<p>This approach provides an alternative to <code>stan_glm</code> with <code>family = binomial()</code> even if the outcome variable has only two categories. The <code>stan_glm</code> function has more options for the prior on the coefficients and the prior on the intercept (which can be interpreted as the first cutpoint when <span class="math inline">\(J = 2\)</span>). However, it may be more difficult to obtain efficient sampling with those priors.</p>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
